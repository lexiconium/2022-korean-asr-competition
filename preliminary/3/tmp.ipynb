{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchaudio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def _dB2Linear(x: float) -> float:\n",
    "    return math.exp(x * math.log(10) / 20.0)\n",
    "\n",
    "\n",
    "def _generate_wave_table(\n",
    "    wave_type: str,\n",
    "    data_type: str,\n",
    "    table_size: int,\n",
    "    min: float,\n",
    "    max: float,\n",
    "    phase: float,\n",
    "    device: torch.device,\n",
    ") -> Tensor:\n",
    "    r\"\"\"A helper function for phaser. Generates a table with given parameters.\n",
    "\n",
    "    Args:\n",
    "        wave_type (str): SINE or TRIANGULAR\n",
    "        data_type (str): desired data_type ( `INT` or `FLOAT` )\n",
    "        table_size (int): desired table size\n",
    "        min (float): desired min value\n",
    "        max (float): desired max value\n",
    "        phase (float): desired phase\n",
    "        device (torch.device): Torch device on which table must be generated\n",
    "    Returns:\n",
    "        Tensor: A 1D tensor with wave table values\n",
    "    \"\"\"\n",
    "\n",
    "    phase_offset = int(phase / math.pi / 2 * table_size + 0.5)\n",
    "\n",
    "    t = torch.arange(table_size, device=device, dtype=torch.int32)\n",
    "\n",
    "    point = (t + phase_offset) % table_size\n",
    "\n",
    "    d = torch.zeros_like(point, device=device, dtype=torch.float64)\n",
    "\n",
    "    if wave_type == \"SINE\":\n",
    "        d = (torch.sin(point.to(torch.float64) / table_size * 2 * math.pi) + 1) / 2\n",
    "    elif wave_type == \"TRIANGLE\":\n",
    "        d = point.to(torch.float64) * 2 / table_size\n",
    "        value = torch.div(4 * point, table_size, rounding_mode=\"floor\")\n",
    "        d[value == 0] = d[value == 0] + 0.5\n",
    "        d[value == 1] = 1.5 - d[value == 1]\n",
    "        d[value == 2] = 1.5 - d[value == 2]\n",
    "        d[value == 3] = d[value == 3] - 1.5\n",
    "\n",
    "    d = d * (max - min) + min\n",
    "\n",
    "    if data_type == \"INT\":\n",
    "        mask = d < 0\n",
    "        d[mask] = d[mask] - 0.5\n",
    "        d[~mask] = d[~mask] + 0.5\n",
    "        d = d.to(torch.int32)\n",
    "    elif data_type == \"FLOAT\":\n",
    "        d = d.to(torch.float32)\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def allpass_biquad(waveform: Tensor, sample_rate: int, central_freq: float, Q: float = 0.707) -> Tensor:\n",
    "    r\"\"\"Design two-pole all-pass filter.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform(torch.Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        central_freq (float or torch.Tensor): central frequency (in Hz)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "\n",
    "    b0 = 1 - alpha\n",
    "    b1 = -2 * torch.cos(w0)\n",
    "    b2 = 1 + alpha\n",
    "    a0 = 1 + alpha\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def band_biquad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    central_freq: float,\n",
    "    Q: float = 0.707,\n",
    "    noise: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Design two-pole band filter.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        central_freq (float or torch.Tensor): central frequency (in Hz)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``).\n",
    "        noise (bool, optional) : If ``True``, uses the alternate mode for un-pitched audio (e.g. percussion).\n",
    "            If ``False``, uses mode oriented to pitched audio, i.e. voice, singing,\n",
    "            or instrumental music (Default: ``False``).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    bw_Hz = central_freq / Q\n",
    "\n",
    "    a0 = 1.0\n",
    "    a2 = torch.exp(-2 * math.pi * bw_Hz / sample_rate)\n",
    "    a1 = -4 * a2 / (1 + a2) * torch.cos(w0)\n",
    "\n",
    "    b0 = torch.sqrt(1 - a1 * a1 / (4 * a2)) * (1 - a2)\n",
    "\n",
    "    if noise:\n",
    "        mult = torch.sqrt(((1 + a2) * (1 + a2) - a1 * a1) * (1 - a2) / (1 + a2)) / b0\n",
    "        b0 = mult * b0\n",
    "\n",
    "    b1 = 0.0\n",
    "    b2 = 0.0\n",
    "\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def bandpass_biquad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    central_freq: float,\n",
    "    Q: float = 0.707,\n",
    "    const_skirt_gain: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Design two-pole band-pass filter.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        central_freq (float or torch.Tensor): central frequency (in Hz)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "        const_skirt_gain (bool, optional) : If ``True``, uses a constant skirt gain (peak gain = Q).\n",
    "            If ``False``, uses a constant 0dB peak gain. (Default: ``False``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "\n",
    "    temp = torch.sin(w0) / 2 if const_skirt_gain else alpha\n",
    "    b0 = temp\n",
    "    b1 = 0.0\n",
    "    b2 = -temp\n",
    "    a0 = 1 + alpha\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def bandreject_biquad(waveform: Tensor, sample_rate: int, central_freq: float, Q: float = 0.707) -> Tensor:\n",
    "    r\"\"\"Design two-pole band-reject filter.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        central_freq (float or torch.Tensor): central frequency (in Hz)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "\n",
    "    b0 = 1.0\n",
    "    b1 = -2 * torch.cos(w0)\n",
    "    b2 = 1.0\n",
    "    a0 = 1 + alpha\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def bass_biquad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    gain: float,\n",
    "    central_freq: float = 100,\n",
    "    Q: float = 0.707,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Design a bass tone-control effect.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        gain (float or torch.Tensor): desired gain at the boost (or attenuation) in dB.\n",
    "        central_freq (float or torch.Tensor, optional): central frequency (in Hz). (Default: ``100``)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "    gain = torch.as_tensor(gain, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "    A = torch.exp(gain / 40 * math.log(10))\n",
    "\n",
    "    temp1 = 2 * torch.sqrt(A) * alpha\n",
    "    temp2 = (A - 1) * torch.cos(w0)\n",
    "    temp3 = (A + 1) * torch.cos(w0)\n",
    "\n",
    "    b0 = A * ((A + 1) - temp2 + temp1)\n",
    "    b1 = 2 * A * ((A - 1) - temp3)\n",
    "    b2 = A * ((A + 1) - temp2 - temp1)\n",
    "    a0 = (A + 1) + temp2 + temp1\n",
    "    a1 = -2 * ((A - 1) + temp3)\n",
    "    a2 = (A + 1) + temp2 - temp1\n",
    "\n",
    "    return biquad(waveform, b0 / a0, b1 / a0, b2 / a0, a0 / a0, a1 / a0, a2 / a0)\n",
    "\n",
    "\n",
    "def biquad(waveform: Tensor, b0: float, b1: float, b2: float, a0: float, a1: float, a2: float) -> Tensor:\n",
    "    r\"\"\"Perform a biquad filter of input tensor.  Initial conditions set to 0.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        b0 (float or torch.Tensor): numerator coefficient of current input, x[n]\n",
    "        b1 (float or torch.Tensor): numerator coefficient of input one time step ago x[n-1]\n",
    "        b2 (float or torch.Tensor): numerator coefficient of input two time steps ago x[n-2]\n",
    "        a0 (float or torch.Tensor): denominator coefficient of current output y[n], typically 1\n",
    "        a1 (float or torch.Tensor): denominator coefficient of current output y[n-1]\n",
    "        a2 (float or torch.Tensor): denominator coefficient of current output y[n-2]\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform with dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "       - https://en.wikipedia.org/wiki/Digital_biquad_filter\n",
    "    \"\"\"\n",
    "\n",
    "    device = waveform.device\n",
    "    dtype = waveform.dtype\n",
    "\n",
    "    b0 = torch.as_tensor(b0, dtype=dtype, device=device).view(1)\n",
    "    b1 = torch.as_tensor(b1, dtype=dtype, device=device).view(1)\n",
    "    b2 = torch.as_tensor(b2, dtype=dtype, device=device).view(1)\n",
    "    a0 = torch.as_tensor(a0, dtype=dtype, device=device).view(1)\n",
    "    a1 = torch.as_tensor(a1, dtype=dtype, device=device).view(1)\n",
    "    a2 = torch.as_tensor(a2, dtype=dtype, device=device).view(1)\n",
    "\n",
    "    output_waveform = lfilter(\n",
    "        waveform,\n",
    "        torch.cat([a0, a1, a2]),\n",
    "        torch.cat([b0, b1, b2]),\n",
    "    )\n",
    "    return output_waveform\n",
    "\n",
    "\n",
    "def contrast(waveform: Tensor, enhancement_amount: float = 75.0) -> Tensor:\n",
    "    r\"\"\"Apply contrast effect.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Comparable with compression, this effect modifies an audio signal to make it sound louder\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        enhancement_amount (float, optional): controls the amount of the enhancement\n",
    "            Allowed range of values for enhancement_amount : 0-100\n",
    "            Note that enhancement_amount = 0 still gives a significant contrast enhancement\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "    \"\"\"\n",
    "\n",
    "    if not 0 <= enhancement_amount <= 100:\n",
    "        raise ValueError(\"Allowed range of values for enhancement_amount : 0-100\")\n",
    "\n",
    "    contrast = enhancement_amount / 750.0\n",
    "\n",
    "    temp1 = waveform * (math.pi / 2)\n",
    "    temp2 = contrast * torch.sin(temp1 * 4)\n",
    "    output_waveform = torch.sin(temp1 + temp2)\n",
    "\n",
    "    return output_waveform\n",
    "\n",
    "\n",
    "def dcshift(waveform: Tensor, shift: float, limiter_gain: Optional[float] = None) -> Tensor:\n",
    "    r\"\"\"Apply a DC shift to the audio. Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: TorchScript\n",
    "\n",
    "    This can be useful to remove a DC offset\n",
    "    (caused perhaps by a hardware problem in the recording chain) from the audio\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        shift (float): indicates the amount to shift the audio\n",
    "            Allowed range of values for shift : -2.0 to +2.0\n",
    "        limiter_gain (float of None, optional): It is used only on peaks to prevent clipping\n",
    "            It should have a value much less than 1 (e.g. 0.05 or 0.02)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "    \"\"\"\n",
    "    output_waveform = waveform\n",
    "    limiter_threshold = 0.0\n",
    "\n",
    "    if limiter_gain is not None:\n",
    "        limiter_threshold = 1.0 - (abs(shift) - limiter_gain)\n",
    "\n",
    "    # Note:\n",
    "    # the following index-based update breaks auto-grad support\n",
    "    if limiter_gain is not None and shift > 0:\n",
    "        mask = waveform > limiter_threshold\n",
    "        temp = (waveform[mask] - limiter_threshold) * limiter_gain / (1 - limiter_threshold)\n",
    "        output_waveform[mask] = (temp + limiter_threshold + shift).clamp(max=limiter_threshold)\n",
    "        output_waveform[~mask] = (waveform[~mask] + shift).clamp(min=-1, max=1)\n",
    "    elif limiter_gain is not None and shift < 0:\n",
    "        mask = waveform < -limiter_threshold\n",
    "        temp = (waveform[mask] + limiter_threshold) * limiter_gain / (1 - limiter_threshold)\n",
    "        output_waveform[mask] = (temp - limiter_threshold + shift).clamp(min=-limiter_threshold)\n",
    "        output_waveform[~mask] = (waveform[~mask] + shift).clamp(min=-1, max=1)\n",
    "    else:\n",
    "        output_waveform = (waveform + shift).clamp(min=-1, max=1)\n",
    "\n",
    "    return output_waveform\n",
    "\n",
    "\n",
    "def deemph_biquad(waveform: Tensor, sample_rate: int) -> Tensor:\n",
    "    r\"\"\"Apply ISO 908 CD de-emphasis (shelving) IIR filter.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, Allowed sample rate ``44100`` or ``48000``\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "\n",
    "    if sample_rate == 44100:\n",
    "        central_freq = 5283\n",
    "        width_slope = 0.4845\n",
    "        gain = -9.477\n",
    "    elif sample_rate == 48000:\n",
    "        central_freq = 5356\n",
    "        width_slope = 0.479\n",
    "        gain = -9.62\n",
    "    else:\n",
    "        raise ValueError(\"Sample rate must be 44100 (audio-CD) or 48000 (DAT)\")\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    A = math.exp(gain / 40.0 * math.log(10))\n",
    "    alpha = math.sin(w0) / 2 * math.sqrt((A + 1 / A) * (1 / width_slope - 1) + 2)\n",
    "\n",
    "    temp1 = 2 * math.sqrt(A) * alpha\n",
    "    temp2 = (A - 1) * math.cos(w0)\n",
    "    temp3 = (A + 1) * math.cos(w0)\n",
    "\n",
    "    b0 = A * ((A + 1) + temp2 + temp1)\n",
    "    b1 = -2 * A * ((A - 1) + temp3)\n",
    "    b2 = A * ((A + 1) + temp2 - temp1)\n",
    "    a0 = (A + 1) - temp2 + temp1\n",
    "    a1 = 2 * ((A - 1) - temp3)\n",
    "    a2 = (A + 1) - temp2 - temp1\n",
    "\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def _add_noise_shaping(dithered_waveform: Tensor, waveform: Tensor) -> Tensor:\n",
    "    r\"\"\"Noise shaping is calculated by error:\n",
    "    error[n] = dithered[n] - original[n]\n",
    "    noise_shaped_waveform[n] = dithered[n] + error[n-1]\n",
    "    \"\"\"\n",
    "    wf_shape = waveform.size()\n",
    "    waveform = waveform.reshape(-1, wf_shape[-1])\n",
    "\n",
    "    dithered_shape = dithered_waveform.size()\n",
    "    dithered_waveform = dithered_waveform.reshape(-1, dithered_shape[-1])\n",
    "\n",
    "    error = dithered_waveform - waveform\n",
    "\n",
    "    # add error[n-1] to dithered_waveform[n], so offset the error by 1 index\n",
    "    zeros = torch.zeros(1, dtype=error.dtype, device=error.device)\n",
    "    for index in range(error.size()[0]):\n",
    "        err = error[index]\n",
    "        error_offset = torch.cat((zeros, err))\n",
    "        error[index] = error_offset[: waveform.size()[1]]\n",
    "\n",
    "    noise_shaped = dithered_waveform + error\n",
    "    return noise_shaped.reshape(dithered_shape[:-1] + noise_shaped.shape[-1:])\n",
    "\n",
    "\n",
    "def _apply_probability_distribution(waveform: Tensor, density_function: str = \"TPDF\") -> Tensor:\n",
    "    r\"\"\"Apply a probability distribution function on a waveform.\n",
    "\n",
    "    Triangular probability density function (TPDF) dither noise has a\n",
    "    triangular distribution; values in the center of the range have a higher\n",
    "    probability of occurring.\n",
    "\n",
    "    Rectangular probability density function (RPDF) dither noise has a\n",
    "    uniform distribution; any value in the specified range has the same\n",
    "    probability of occurring.\n",
    "\n",
    "    Gaussian probability density function (GPDF) has a normal distribution.\n",
    "    The relationship of probabilities of results follows a bell-shaped,\n",
    "    or Gaussian curve, typical of dither generated by analog sources.\n",
    "    Args:\n",
    "        waveform (Tensor): Tensor of audio of dimension (..., time)\n",
    "        density_function (str, optional): The density function of a\n",
    "           continuous random variable (Default: ``\"TPDF\"``)\n",
    "           Options: Triangular Probability Density Function - `TPDF`\n",
    "                    Rectangular Probability Density Function - `RPDF`\n",
    "                    Gaussian Probability Density Function - `GPDF`\n",
    "    Returns:\n",
    "        Tensor: waveform dithered with TPDF\n",
    "    \"\"\"\n",
    "\n",
    "    # pack batch\n",
    "    shape = waveform.size()\n",
    "    waveform = waveform.reshape(-1, shape[-1])\n",
    "\n",
    "    channel_size = waveform.size()[0] - 1\n",
    "    time_size = waveform.size()[-1] - 1\n",
    "\n",
    "    random_channel = (\n",
    "        int(\n",
    "            torch.randint(\n",
    "                channel_size,\n",
    "                [\n",
    "                    1,\n",
    "                ],\n",
    "            ).item()\n",
    "        )\n",
    "        if channel_size > 0\n",
    "        else 0\n",
    "    )\n",
    "    random_time = (\n",
    "        int(\n",
    "            torch.randint(\n",
    "                time_size,\n",
    "                [\n",
    "                    1,\n",
    "                ],\n",
    "            ).item()\n",
    "        )\n",
    "        if time_size > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    number_of_bits = 16\n",
    "    up_scaling = 2 ** (number_of_bits - 1) - 2\n",
    "    signal_scaled = waveform * up_scaling\n",
    "    down_scaling = 2 ** (number_of_bits - 1)\n",
    "\n",
    "    signal_scaled_dis = waveform\n",
    "    if density_function == \"RPDF\":\n",
    "        RPDF = waveform[random_channel][random_time] - 0.5\n",
    "\n",
    "        signal_scaled_dis = signal_scaled + RPDF\n",
    "    elif density_function == \"GPDF\":\n",
    "        # TODO Replace by distribution code once\n",
    "        # https://github.com/pytorch/pytorch/issues/29843 is resolved\n",
    "        # gaussian = torch.distributions.normal.Normal(torch.mean(waveform, -1), 1).sample()\n",
    "\n",
    "        num_rand_variables = 6\n",
    "\n",
    "        gaussian = waveform[random_channel][random_time]\n",
    "        for ws in num_rand_variables * [time_size]:\n",
    "            rand_chan = int(\n",
    "                torch.randint(\n",
    "                    channel_size,\n",
    "                    [\n",
    "                        1,\n",
    "                    ],\n",
    "                ).item()\n",
    "            )\n",
    "            gaussian += waveform[rand_chan][\n",
    "                int(\n",
    "                    torch.randint(\n",
    "                        ws,\n",
    "                        [\n",
    "                            1,\n",
    "                        ],\n",
    "                    ).item()\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        signal_scaled_dis = signal_scaled + gaussian\n",
    "    else:\n",
    "        # dtype needed for https://github.com/pytorch/pytorch/issues/32358\n",
    "        TPDF = torch.bartlett_window(time_size + 1, dtype=signal_scaled.dtype, device=signal_scaled.device)\n",
    "        TPDF = TPDF.repeat((channel_size + 1), 1)\n",
    "        signal_scaled_dis = signal_scaled + TPDF\n",
    "\n",
    "    quantised_signal_scaled = torch.round(signal_scaled_dis)\n",
    "    quantised_signal = quantised_signal_scaled / down_scaling\n",
    "\n",
    "    # unpack batch\n",
    "    return quantised_signal.reshape(shape[:-1] + quantised_signal.shape[-1:])\n",
    "\n",
    "\n",
    "def dither(waveform: Tensor, density_function: str = \"TPDF\", noise_shaping: bool = False) -> Tensor:\n",
    "    r\"\"\"Apply dither\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: TorchScript\n",
    "\n",
    "    Dither increases the perceived dynamic range of audio stored at a\n",
    "    particular bit-depth by eliminating nonlinear truncation distortion\n",
    "    (i.e. adding minimally perceived noise to mask distortion caused by quantization).\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): Tensor of audio of dimension (..., time)\n",
    "        density_function (str, optional):\n",
    "            The density function of a continuous random variable. One of\n",
    "            ``\"TPDF\"`` (Triangular Probability Density Function),\n",
    "            ``\"RPDF\"`` (Rectangular Probability Density Function) or\n",
    "            ``\"GPDF\"`` (Gaussian Probability Density Function) (Default: ``\"TPDF\"``).\n",
    "        noise_shaping (bool, optional): a filtering process that shapes the spectral\n",
    "            energy of quantisation error (Default: ``False``)\n",
    "\n",
    "    Returns:\n",
    "       Tensor: waveform dithered\n",
    "    \"\"\"\n",
    "    dithered = _apply_probability_distribution(waveform, density_function=density_function)\n",
    "\n",
    "    if noise_shaping:\n",
    "        return _add_noise_shaping(dithered, waveform)\n",
    "    else:\n",
    "        return dithered\n",
    "\n",
    "\n",
    "def equalizer_biquad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    center_freq: float,\n",
    "    gain: float,\n",
    "    Q: float = 0.707,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Design biquad peaking equalizer filter and perform filtering.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        center_freq (float): filter's central frequency\n",
    "        gain (float or torch.Tensor): desired gain at the boost (or attenuation) in dB\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    center_freq = torch.as_tensor(center_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "    gain = torch.as_tensor(gain, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * center_freq / sample_rate\n",
    "    A = torch.exp(gain / 40.0 * math.log(10))\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "\n",
    "    b0 = 1 + alpha * A\n",
    "    b1 = -2 * torch.cos(w0)\n",
    "    b2 = 1 - alpha * A\n",
    "    a0 = 1 + alpha / A\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha / A\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def filtfilt(\n",
    "    waveform: Tensor,\n",
    "    a_coeffs: Tensor,\n",
    "    b_coeffs: Tensor,\n",
    "    clamp: bool = True,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Apply an IIR filter forward and backward to a waveform.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Inspired by https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`.  Must be normalized to -1 to 1.\n",
    "        a_coeffs (Tensor): denominator coefficients of difference equation of dimension of either\n",
    "                                1D with shape `(num_order + 1)` or 2D with shape `(num_filters, num_order + 1)`.\n",
    "                                Lower delay coefficients are first, e.g. ``[a0, a1, a2, ...]``.\n",
    "                                Must be same size as b_coeffs (pad with 0's as necessary).\n",
    "        b_coeffs (Tensor): numerator coefficients of difference equation of dimension of either\n",
    "                                1D with shape `(num_order + 1)` or 2D with shape `(num_filters, num_order + 1)`.\n",
    "                                Lower delay coefficients are first, e.g. ``[b0, b1, b2, ...]``.\n",
    "                                Must be same size as a_coeffs (pad with 0's as necessary).\n",
    "        clamp (bool, optional): If ``True``, clamp the output signal to be in the range [-1, 1] (Default: ``True``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform with dimension of either `(..., num_filters, time)` if ``a_coeffs`` and ``b_coeffs``\n",
    "        are 2D Tensors, or `(..., time)` otherwise.\n",
    "    \"\"\"\n",
    "    forward_filtered = lfilter(waveform, a_coeffs, b_coeffs, clamp=False, batching=True)\n",
    "    backward_filtered = lfilter(\n",
    "        forward_filtered.flip(-1),\n",
    "        a_coeffs,\n",
    "        b_coeffs,\n",
    "        clamp=clamp,\n",
    "        batching=True,\n",
    "    ).flip(-1)\n",
    "    return backward_filtered\n",
    "\n",
    "\n",
    "def flanger(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    delay: float = 0.0,\n",
    "    depth: float = 2.0,\n",
    "    regen: float = 0.0,\n",
    "    width: float = 71.0,\n",
    "    speed: float = 0.5,\n",
    "    phase: float = 25.0,\n",
    "    modulation: str = \"sinusoidal\",\n",
    "    interpolation: str = \"linear\",\n",
    ") -> Tensor:\n",
    "    r\"\"\"Apply a flanger effect to the audio. Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., channel, time)` .\n",
    "            Max 4 channels allowed\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        delay (float, optional): desired delay in milliseconds(ms)\n",
    "            Allowed range of values are 0 to 30\n",
    "        depth (float, optional): desired delay depth in milliseconds(ms)\n",
    "            Allowed range of values are 0 to 10\n",
    "        regen (float, optional): desired regen(feedback gain) in dB\n",
    "            Allowed range of values are -95 to 95\n",
    "        width (float, optional):  desired width(delay gain) in dB\n",
    "            Allowed range of values are 0 to 100\n",
    "        speed (float, optional):  modulation speed in Hz\n",
    "            Allowed range of values are 0.1 to 10\n",
    "        phase (float, optional):  percentage phase-shift for multi-channel\n",
    "            Allowed range of values are 0 to 100\n",
    "        modulation (str, optional):  Use either \"sinusoidal\" or \"triangular\" modulation. (Default: ``sinusoidal``)\n",
    "        interpolation (str, optional): Use either \"linear\" or \"quadratic\" for delay-line interpolation.\n",
    "            (Default: ``linear``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., channel, time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "\n",
    "        - Scott Lehman, `Effects Explained`_,\n",
    "\n",
    "    .. _Effects Explained:\n",
    "        https://web.archive.org/web/20051125072557/http://www.harmony-central.com/Effects/effects-explained.html\n",
    "    \"\"\"\n",
    "\n",
    "    if modulation not in (\"sinusoidal\", \"triangular\"):\n",
    "        raise ValueError(\"Only 'sinusoidal' or 'triangular' modulation allowed\")\n",
    "\n",
    "    if interpolation not in (\"linear\", \"quadratic\"):\n",
    "        raise ValueError(\"Only 'linear' or 'quadratic' interpolation allowed\")\n",
    "\n",
    "    actual_shape = waveform.shape\n",
    "    device, dtype = waveform.device, waveform.dtype\n",
    "\n",
    "    if actual_shape[-2] > 4:\n",
    "        raise ValueError(\"Max 4 channels allowed\")\n",
    "\n",
    "    # convert to 3D (batch, channels, time)\n",
    "    waveform = waveform.view(-1, actual_shape[-2], actual_shape[-1])\n",
    "\n",
    "    # Scaling\n",
    "    feedback_gain = regen / 100\n",
    "    delay_gain = width / 100\n",
    "    channel_phase = phase / 100\n",
    "    delay_min = delay / 1000\n",
    "    delay_depth = depth / 1000\n",
    "\n",
    "    n_channels = waveform.shape[-2]\n",
    "\n",
    "    if modulation == \"sinusoidal\":\n",
    "        wave_type = \"SINE\"\n",
    "    else:\n",
    "        wave_type = \"TRIANGLE\"\n",
    "\n",
    "    # Balance output:\n",
    "    in_gain = 1.0 / (1 + delay_gain)\n",
    "    delay_gain = delay_gain / (1 + delay_gain)\n",
    "\n",
    "    # Balance feedback loop:\n",
    "    delay_gain = delay_gain * (1 - abs(feedback_gain))\n",
    "\n",
    "    delay_buf_length = int((delay_min + delay_depth) * sample_rate + 0.5)\n",
    "    delay_buf_length = delay_buf_length + 2\n",
    "\n",
    "    delay_bufs = torch.zeros(waveform.shape[0], n_channels, delay_buf_length, dtype=dtype, device=device)\n",
    "    delay_last = torch.zeros(waveform.shape[0], n_channels, dtype=dtype, device=device)\n",
    "\n",
    "    lfo_length = int(sample_rate / speed)\n",
    "\n",
    "    table_min = math.floor(delay_min * sample_rate + 0.5)\n",
    "    table_max = delay_buf_length - 2.0\n",
    "\n",
    "    lfo = _generate_wave_table(\n",
    "        wave_type=wave_type,\n",
    "        data_type=\"FLOAT\",\n",
    "        table_size=lfo_length,\n",
    "        min=float(table_min),\n",
    "        max=float(table_max),\n",
    "        phase=3 * math.pi / 2,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    output_waveform = torch.zeros_like(waveform, dtype=dtype, device=device)\n",
    "\n",
    "    delay_buf_pos = 0\n",
    "    lfo_pos = 0\n",
    "    channel_idxs = torch.arange(0, n_channels, device=device)\n",
    "\n",
    "    for i in range(waveform.shape[-1]):\n",
    "\n",
    "        delay_buf_pos = (delay_buf_pos + delay_buf_length - 1) % delay_buf_length\n",
    "\n",
    "        cur_channel_phase = (channel_idxs * lfo_length * channel_phase + 0.5).to(torch.int64)\n",
    "        delay_tensor = lfo[(lfo_pos + cur_channel_phase) % lfo_length]\n",
    "        frac_delay = torch.frac(delay_tensor)\n",
    "        delay_tensor = torch.floor(delay_tensor)\n",
    "\n",
    "        int_delay = delay_tensor.to(torch.int64)\n",
    "\n",
    "        temp = waveform[:, :, i]\n",
    "\n",
    "        delay_bufs[:, :, delay_buf_pos] = temp + delay_last * feedback_gain\n",
    "\n",
    "        delayed_0 = delay_bufs[:, channel_idxs, (delay_buf_pos + int_delay) % delay_buf_length]\n",
    "\n",
    "        int_delay = int_delay + 1\n",
    "\n",
    "        delayed_1 = delay_bufs[:, channel_idxs, (delay_buf_pos + int_delay) % delay_buf_length]\n",
    "\n",
    "        int_delay = int_delay + 1\n",
    "\n",
    "        if interpolation == \"linear\":\n",
    "            delayed = delayed_0 + (delayed_1 - delayed_0) * frac_delay\n",
    "        else:\n",
    "            delayed_2 = delay_bufs[:, channel_idxs, (delay_buf_pos + int_delay) % delay_buf_length]\n",
    "\n",
    "            int_delay = int_delay + 1\n",
    "\n",
    "            delayed_2 = delayed_2 - delayed_0\n",
    "            delayed_1 = delayed_1 - delayed_0\n",
    "            a = delayed_2 * 0.5 - delayed_1\n",
    "            b = delayed_1 * 2 - delayed_2 * 0.5\n",
    "\n",
    "            delayed = delayed_0 + (a * frac_delay + b) * frac_delay\n",
    "\n",
    "        delay_last = delayed\n",
    "        output_waveform[:, :, i] = waveform[:, :, i] * in_gain + delayed * delay_gain\n",
    "\n",
    "        lfo_pos = (lfo_pos + 1) % lfo_length\n",
    "\n",
    "    return output_waveform.clamp(min=-1, max=1).view(actual_shape)\n",
    "\n",
    "\n",
    "def gain(waveform: Tensor, gain_db: float = 1.0) -> Tensor:\n",
    "    r\"\"\"Apply amplification or attenuation to the whole waveform.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "       waveform (Tensor): Tensor of audio of dimension (..., time).\n",
    "       gain_db (float, optional) Gain adjustment in decibels (dB) (Default: ``1.0``).\n",
    "\n",
    "    Returns:\n",
    "       Tensor: the whole waveform amplified by gain_db.\n",
    "    \"\"\"\n",
    "    if gain_db == 0:\n",
    "        return waveform\n",
    "\n",
    "    ratio = 10 ** (gain_db / 20)\n",
    "\n",
    "    return waveform * ratio\n",
    "\n",
    "\n",
    "def highpass_biquad(waveform: Tensor, sample_rate: int, cutoff_freq: float, Q: float = 0.707) -> Tensor:\n",
    "    r\"\"\"Design biquad highpass filter and perform filtering.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        cutoff_freq (float or torch.Tensor): filter cutoff frequency\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform dimension of `(..., time)`\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    cutoff_freq = torch.as_tensor(cutoff_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * cutoff_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2.0 / Q\n",
    "\n",
    "    b0 = (1 + torch.cos(w0)) / 2\n",
    "    b1 = -1 - torch.cos(w0)\n",
    "    b2 = b0\n",
    "    a0 = 1 + alpha\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def _lfilter_core_generic_loop(input_signal_windows: Tensor, a_coeffs_flipped: Tensor, padded_output_waveform: Tensor):\n",
    "    n_order = a_coeffs_flipped.size(1)\n",
    "    a_coeffs_flipped = a_coeffs_flipped.unsqueeze(2)\n",
    "    for i_sample, o0 in enumerate(input_signal_windows.permute(2, 0, 1)):\n",
    "        windowed_output_signal = padded_output_waveform[:, :, i_sample: i_sample + n_order]\n",
    "        o0 -= (windowed_output_signal.transpose(0, 1) @ a_coeffs_flipped)[..., 0].t()\n",
    "        padded_output_waveform[:, :, i_sample + n_order - 1] = o0\n",
    "\n",
    "\n",
    "try:\n",
    "    _lfilter_core_cpu_loop = torch.ops.torchaudio._lfilter_core_loop\n",
    "except RuntimeError as err:\n",
    "    assert str(err) == \"No such operator torchaudio::_lfilter_core_loop\"\n",
    "    _lfilter_core_cpu_loop = _lfilter_core_generic_loop\n",
    "\n",
    "\n",
    "def _lfilter_core(\n",
    "    waveform: Tensor,\n",
    "    a_coeffs: Tensor,\n",
    "    b_coeffs: Tensor,\n",
    ") -> Tensor:\n",
    "\n",
    "    assert a_coeffs.size() == b_coeffs.size()\n",
    "    assert len(waveform.size()) == 3\n",
    "    assert waveform.device == a_coeffs.device\n",
    "    assert b_coeffs.device == a_coeffs.device\n",
    "\n",
    "    n_batch, n_channel, n_sample = waveform.size()\n",
    "    n_order = a_coeffs.size(1)\n",
    "    assert n_order > 0\n",
    "\n",
    "    # Pad the input and create output\n",
    "\n",
    "    padded_waveform = torch.nn.functional.pad(waveform, [n_order - 1, 0])\n",
    "    padded_output_waveform = torch.zeros_like(padded_waveform)\n",
    "\n",
    "    # Set up the coefficients matrix\n",
    "    # Flip coefficients' order\n",
    "    a_coeffs_flipped = a_coeffs.flip(1)\n",
    "    b_coeffs_flipped = b_coeffs.flip(1)\n",
    "\n",
    "    # calculate windowed_input_signal in parallel using convolution\n",
    "    input_signal_windows = torch.nn.functional.conv1d(padded_waveform, b_coeffs_flipped.unsqueeze(1), groups=n_channel)\n",
    "\n",
    "    input_signal_windows.div_(a_coeffs[:, :1])\n",
    "    a_coeffs_flipped.div_(a_coeffs[:, :1])\n",
    "\n",
    "    if (\n",
    "        input_signal_windows.device == torch.device(\"cpu\")\n",
    "        and a_coeffs_flipped.device == torch.device(\"cpu\")\n",
    "        and padded_output_waveform.device == torch.device(\"cpu\")\n",
    "    ):\n",
    "        _lfilter_core_cpu_loop(input_signal_windows, a_coeffs_flipped, padded_output_waveform)\n",
    "    else:\n",
    "        _lfilter_core_generic_loop(input_signal_windows, a_coeffs_flipped, padded_output_waveform)\n",
    "\n",
    "    output = padded_output_waveform[:, :, n_order - 1:]\n",
    "    return output\n",
    "\n",
    "\n",
    "try:\n",
    "    _lfilter = torch.ops.torchaudio._lfilter\n",
    "except RuntimeError as err:\n",
    "    assert str(err) == \"No such operator torchaudio::_lfilter\"\n",
    "    _lfilter = _lfilter_core\n",
    "\n",
    "\n",
    "def lfilter(waveform: Tensor, a_coeffs: Tensor, b_coeffs: Tensor, clamp: bool = True, batching: bool = True) -> Tensor:\n",
    "    r\"\"\"Perform an IIR filter by evaluating difference equation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Note:\n",
    "        To avoid numerical problems, small filter order is preferred.\n",
    "        Using double precision could also minimize numerical precision errors.\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`.  Must be normalized to -1 to 1.\n",
    "        a_coeffs (Tensor): denominator coefficients of difference equation of dimension of either\n",
    "                                1D with shape `(num_order + 1)` or 2D with shape `(num_filters, num_order + 1)`.\n",
    "                                Lower delays coefficients are first, e.g. ``[a0, a1, a2, ...]``.\n",
    "                                Must be same size as b_coeffs (pad with 0's as necessary).\n",
    "        b_coeffs (Tensor): numerator coefficients of difference equation of dimension of either\n",
    "                                1D with shape `(num_order + 1)` or 2D with shape `(num_filters, num_order + 1)`.\n",
    "                                Lower delays coefficients are first, e.g. ``[b0, b1, b2, ...]``.\n",
    "                                Must be same size as a_coeffs (pad with 0's as necessary).\n",
    "        clamp (bool, optional): If ``True``, clamp the output signal to be in the range [-1, 1] (Default: ``True``)\n",
    "        batching (bool, optional): Effective only when coefficients are 2D. If ``True``, then waveform should be at\n",
    "                                    least 2D, and the size of second axis from last should equals to ``num_filters``.\n",
    "                                    The output can be expressed as ``output[..., i, :] = lfilter(waveform[..., i, :],\n",
    "                                    a_coeffs[i], b_coeffs[i], clamp=clamp, batching=False)``. (Default: ``True``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform with dimension of either `(..., num_filters, time)` if ``a_coeffs`` and ``b_coeffs``\n",
    "        are 2D Tensors, or `(..., time)` otherwise.\n",
    "    \"\"\"\n",
    "    assert a_coeffs.size() == b_coeffs.size()\n",
    "    assert a_coeffs.ndim <= 2\n",
    "\n",
    "    if a_coeffs.ndim > 1:\n",
    "        if batching:\n",
    "            assert waveform.ndim > 1\n",
    "            assert waveform.shape[-2] == a_coeffs.shape[0]\n",
    "        else:\n",
    "            waveform = torch.stack([waveform] * a_coeffs.shape[0], -2)\n",
    "    else:\n",
    "        a_coeffs = a_coeffs.unsqueeze(0)\n",
    "        b_coeffs = b_coeffs.unsqueeze(0)\n",
    "\n",
    "    # pack batch\n",
    "    shape = waveform.size()\n",
    "    waveform = waveform.reshape(-1, a_coeffs.shape[0], shape[-1])\n",
    "    output = _lfilter(waveform, a_coeffs, b_coeffs)\n",
    "\n",
    "    if clamp:\n",
    "        output = torch.clamp(output, min=-1.0, max=1.0)\n",
    "\n",
    "    # unpack batch\n",
    "    output = output.reshape(shape[:-1] + output.shape[-1:])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def lowpass_biquad(waveform: Tensor, sample_rate: int, cutoff_freq: float, Q: float = 0.707) -> Tensor:\n",
    "    r\"\"\"Design biquad lowpass filter and perform filtering.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (torch.Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        cutoff_freq (float or torch.Tensor): filter cutoff frequency\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    cutoff_freq = torch.as_tensor(cutoff_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * cutoff_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "\n",
    "    b0 = (1 - torch.cos(w0)) / 2\n",
    "    b1 = 1 - torch.cos(w0)\n",
    "    b2 = b0\n",
    "    a0 = 1 + alpha\n",
    "    a1 = -2 * torch.cos(w0)\n",
    "    a2 = 1 - alpha\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def _overdrive_core_loop_generic(\n",
    "    waveform: Tensor, temp: Tensor, last_in: Tensor, last_out: Tensor, output_waveform: Tensor\n",
    "):\n",
    "    for i in range(waveform.shape[-1]):\n",
    "        last_out = temp[:, i] - last_in + 0.995 * last_out\n",
    "        last_in = temp[:, i]\n",
    "        output_waveform[:, i] = waveform[:, i] * 0.5 + last_out * 0.75\n",
    "\n",
    "\n",
    "try:\n",
    "    _overdrive_core_loop_cpu = torch.ops.torchaudio._overdrive_core_loop\n",
    "except RuntimeError as err:\n",
    "    assert str(err) == \"No such operator torchaudio::_overdrive_core_loop\"\n",
    "    _overdrive_core_loop_cpu = _overdrive_core_loop_generic\n",
    "\n",
    "\n",
    "def overdrive(waveform: Tensor, gain: float = 20, colour: float = 20) -> Tensor:\n",
    "    r\"\"\"Apply a overdrive effect to the audio. Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    This effect applies a non linear distortion to the audio signal.\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        gain (float, optional): desired gain at the boost (or attenuation) in dB\n",
    "            Allowed range of values are 0 to 100\n",
    "        colour (float, optional):  controls the amount of even harmonic content in the over-driven output\n",
    "            Allowed range of values are 0 to 100\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "    \"\"\"\n",
    "    actual_shape = waveform.shape\n",
    "    device, dtype = waveform.device, waveform.dtype\n",
    "\n",
    "    # convert to 2D (..,time)\n",
    "    waveform = waveform.view(-1, actual_shape[-1])\n",
    "\n",
    "    gain = _dB2Linear(gain)\n",
    "    colour = colour / 200\n",
    "    last_in = torch.zeros(waveform.shape[:-1], dtype=dtype, device=device)\n",
    "    last_out = torch.zeros(waveform.shape[:-1], dtype=dtype, device=device)\n",
    "\n",
    "    temp = waveform * gain + colour\n",
    "\n",
    "    mask1 = temp < -1\n",
    "    temp[mask1] = torch.tensor(-2.0 / 3.0, dtype=dtype, device=device)\n",
    "    # Wrapping the constant with Tensor is required for Torchscript\n",
    "\n",
    "    mask2 = temp > 1\n",
    "    temp[mask2] = torch.tensor(2.0 / 3.0, dtype=dtype, device=device)\n",
    "\n",
    "    mask3 = ~mask1 & ~mask2\n",
    "    temp[mask3] = temp[mask3] - (temp[mask3] ** 3) * (1.0 / 3)\n",
    "\n",
    "    output_waveform = torch.zeros_like(waveform, dtype=dtype, device=device)\n",
    "\n",
    "    # Uses CPU optimized loop function if available for CPU device\n",
    "    if device == torch.device(\"cpu\"):\n",
    "        _overdrive_core_loop_cpu(waveform, temp, last_in, last_out, output_waveform)\n",
    "    else:\n",
    "        _overdrive_core_loop_generic(waveform, temp, last_in, last_out, output_waveform)\n",
    "\n",
    "    return output_waveform.clamp(min=-1, max=1).view(actual_shape)\n",
    "\n",
    "\n",
    "def phaser(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    gain_in: float = 0.4,\n",
    "    gain_out: float = 0.74,\n",
    "    delay_ms: float = 3.0,\n",
    "    decay: float = 0.4,\n",
    "    mod_speed: float = 0.5,\n",
    "    sinusoidal: bool = True,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Apply a phasing effect to the audio. Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        gain_in (float, optional): desired input gain at the boost (or attenuation) in dB\n",
    "            Allowed range of values are 0 to 1\n",
    "        gain_out (float, optional): desired output gain at the boost (or attenuation) in dB\n",
    "            Allowed range of values are 0 to 1e9\n",
    "        delay_ms (float, optional): desired delay in milliseconds\n",
    "            Allowed range of values are 0 to 5.0\n",
    "        decay (float, optional):  desired decay relative to gain-in\n",
    "            Allowed range of values are 0 to 0.99\n",
    "        mod_speed (float, optional):  modulation speed in Hz\n",
    "            Allowed range of values are 0.1 to 2\n",
    "        sinusoidal (bool, optional):  If ``True``, uses sinusoidal modulation (preferable for multiple instruments)\n",
    "            If ``False``, uses triangular modulation (gives single instruments a sharper phasing effect)\n",
    "            (Default: ``True``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - Scott Lehman, `Effects Explained`_.\n",
    "\n",
    "    .. _Effects Explained:\n",
    "        https://web.archive.org/web/20051125072557/http://www.harmony-central.com/Effects/effects-explained.html\n",
    "    \"\"\"\n",
    "    actual_shape = waveform.shape\n",
    "    device, dtype = waveform.device, waveform.dtype\n",
    "\n",
    "    # convert to 2D (channels,time)\n",
    "    waveform = waveform.view(-1, actual_shape[-1])\n",
    "\n",
    "    delay_buf_len = int((delay_ms * 0.001 * sample_rate) + 0.5)\n",
    "    delay_buf = torch.zeros(waveform.shape[0], delay_buf_len, dtype=dtype, device=device)\n",
    "\n",
    "    mod_buf_len = int(sample_rate / mod_speed + 0.5)\n",
    "\n",
    "    if sinusoidal:\n",
    "        wave_type = \"SINE\"\n",
    "    else:\n",
    "        wave_type = \"TRIANGLE\"\n",
    "\n",
    "    mod_buf = _generate_wave_table(\n",
    "        wave_type=wave_type,\n",
    "        data_type=\"INT\",\n",
    "        table_size=mod_buf_len,\n",
    "        min=1.0,\n",
    "        max=float(delay_buf_len),\n",
    "        phase=math.pi / 2,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    delay_pos = 0\n",
    "    mod_pos = 0\n",
    "\n",
    "    output_waveform_pre_gain_list = []\n",
    "    waveform = waveform * gain_in\n",
    "    delay_buf = delay_buf * decay\n",
    "    waveform_list = [waveform[:, i] for i in range(waveform.size(1))]\n",
    "    delay_buf_list = [delay_buf[:, i] for i in range(delay_buf.size(1))]\n",
    "    mod_buf_list = [mod_buf[i] for i in range(mod_buf.size(0))]\n",
    "\n",
    "    for i in range(waveform.shape[-1]):\n",
    "        idx = int((delay_pos + mod_buf_list[mod_pos]) % delay_buf_len)\n",
    "        mod_pos = (mod_pos + 1) % mod_buf_len\n",
    "        delay_pos = (delay_pos + 1) % delay_buf_len\n",
    "        temp = (waveform_list[i]) + (delay_buf_list[idx])\n",
    "        delay_buf_list[delay_pos] = temp * decay\n",
    "        output_waveform_pre_gain_list.append(temp)\n",
    "\n",
    "    output_waveform = torch.stack(output_waveform_pre_gain_list, dim=1).to(dtype=dtype, device=device)\n",
    "    output_waveform.mul_(gain_out)\n",
    "\n",
    "    return output_waveform.clamp(min=-1, max=1).view(actual_shape)\n",
    "\n",
    "\n",
    "def riaa_biquad(waveform: Tensor, sample_rate: int) -> Tensor:\n",
    "    r\"\"\"Apply RIAA vinyl playback equalization.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz).\n",
    "            Allowed sample rates in Hz : ``44100``,``48000``,``88200``,``96000``\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "\n",
    "    if sample_rate == 44100:\n",
    "        zeros = [-0.2014898, 0.9233820]\n",
    "        poles = [0.7083149, 0.9924091]\n",
    "\n",
    "    elif sample_rate == 48000:\n",
    "        zeros = [-0.1766069, 0.9321590]\n",
    "        poles = [0.7396325, 0.9931330]\n",
    "\n",
    "    elif sample_rate == 88200:\n",
    "        zeros = [-0.1168735, 0.9648312]\n",
    "        poles = [0.8590646, 0.9964002]\n",
    "\n",
    "    elif sample_rate == 96000:\n",
    "        zeros = [-0.1141486, 0.9676817]\n",
    "        poles = [0.8699137, 0.9966946]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Sample rate must be 44.1k, 48k, 88.2k, or 96k\")\n",
    "\n",
    "    # polynomial coefficients with roots zeros[0] and zeros[1]\n",
    "    b0 = 1.0\n",
    "    b1 = -(zeros[0] + zeros[1])\n",
    "    b2 = zeros[0] * zeros[1]\n",
    "\n",
    "    # polynomial coefficients with roots poles[0] and poles[1]\n",
    "    a0 = 1.0\n",
    "    a1 = -(poles[0] + poles[1])\n",
    "    a2 = poles[0] * poles[1]\n",
    "\n",
    "    # Normalize to 0dB at 1kHz\n",
    "    y = 2 * math.pi * 1000 / sample_rate\n",
    "    b_re = b0 + b1 * math.cos(-y) + b2 * math.cos(-2 * y)\n",
    "    a_re = a0 + a1 * math.cos(-y) + a2 * math.cos(-2 * y)\n",
    "    b_im = b1 * math.sin(-y) + b2 * math.sin(-2 * y)\n",
    "    a_im = a1 * math.sin(-y) + a2 * math.sin(-2 * y)\n",
    "    g = 1 / math.sqrt((b_re ** 2 + b_im ** 2) / (a_re ** 2 + a_im ** 2))\n",
    "\n",
    "    b0 *= g\n",
    "    b1 *= g\n",
    "    b2 *= g\n",
    "\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def treble_biquad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    gain: float,\n",
    "    central_freq: float = 3000,\n",
    "    Q: float = 0.707,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Design a treble tone-control effect.  Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: Autograd TorchScript\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): audio waveform of dimension of `(..., time)`\n",
    "        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz)\n",
    "        gain (float or torch.Tensor): desired gain at the boost (or attenuation) in dB.\n",
    "        central_freq (float or torch.Tensor, optional): central frequency (in Hz). (Default: ``3000``)\n",
    "        Q (float or torch.Tensor, optional): https://en.wikipedia.org/wiki/Q_factor (Default: ``0.707``).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Waveform of dimension of `(..., time)`\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "        - https://www.w3.org/2011/audio/audio-eq-cookbook.html#APF\n",
    "    \"\"\"\n",
    "    dtype = waveform.dtype\n",
    "    device = waveform.device\n",
    "    central_freq = torch.as_tensor(central_freq, dtype=dtype, device=device)\n",
    "    Q = torch.as_tensor(Q, dtype=dtype, device=device)\n",
    "    gain = torch.as_tensor(gain, dtype=dtype, device=device)\n",
    "\n",
    "    w0 = 2 * math.pi * central_freq / sample_rate\n",
    "    alpha = torch.sin(w0) / 2 / Q\n",
    "    A = torch.exp(gain / 40 * math.log(10))\n",
    "\n",
    "    temp1 = 2 * torch.sqrt(A) * alpha\n",
    "    temp2 = (A - 1) * torch.cos(w0)\n",
    "    temp3 = (A + 1) * torch.cos(w0)\n",
    "\n",
    "    b0 = A * ((A + 1) + temp2 + temp1)\n",
    "    b1 = -2 * A * ((A - 1) + temp3)\n",
    "    b2 = A * ((A + 1) + temp2 - temp1)\n",
    "    a0 = (A + 1) - temp2 + temp1\n",
    "    a1 = 2 * ((A - 1) - temp3)\n",
    "    a2 = (A + 1) - temp2 - temp1\n",
    "\n",
    "    return biquad(waveform, b0, b1, b2, a0, a1, a2)\n",
    "\n",
    "\n",
    "def _measure(\n",
    "    measure_len_ws: int,\n",
    "    samples: Tensor,\n",
    "    spectrum: Tensor,\n",
    "    noise_spectrum: Tensor,\n",
    "    spectrum_window: Tensor,\n",
    "    spectrum_start: int,\n",
    "    spectrum_end: int,\n",
    "    cepstrum_window: Tensor,\n",
    "    cepstrum_start: int,\n",
    "    cepstrum_end: int,\n",
    "    noise_reduction_amount: float,\n",
    "    measure_smooth_time_mult: float,\n",
    "    noise_up_time_mult: float,\n",
    "    noise_down_time_mult: float,\n",
    "    index_ns: int,\n",
    "    boot_count: int,\n",
    ") -> float:\n",
    "\n",
    "    assert spectrum.size()[-1] == noise_spectrum.size()[-1]\n",
    "\n",
    "    samplesLen_ns = samples.size()[-1]\n",
    "    dft_len_ws = spectrum.size()[-1]\n",
    "\n",
    "    dftBuf = torch.zeros(dft_len_ws)\n",
    "\n",
    "    _index_ns = torch.tensor([index_ns] + [(index_ns + i) % samplesLen_ns for i in range(1, measure_len_ws)])\n",
    "    dftBuf[:measure_len_ws] = samples[_index_ns] * spectrum_window[:measure_len_ws]\n",
    "\n",
    "    # memset(c->dftBuf + i, 0, (p->dft_len_ws - i) * sizeof(*c->dftBuf));\n",
    "    dftBuf[measure_len_ws:dft_len_ws].zero_()\n",
    "\n",
    "    # lsx_safe_rdft((int)p->dft_len_ws, 1, c->dftBuf);\n",
    "    _dftBuf = torch.fft.rfft(dftBuf)\n",
    "\n",
    "    # memset(c->dftBuf, 0, p->spectrum_start * sizeof(*c->dftBuf));\n",
    "    _dftBuf[:spectrum_start].zero_()\n",
    "\n",
    "    mult: float = boot_count / (1.0 + boot_count) if boot_count >= 0 else measure_smooth_time_mult\n",
    "\n",
    "    _d = _dftBuf[spectrum_start:spectrum_end].abs()\n",
    "    spectrum[spectrum_start:spectrum_end].mul_(mult).add_(_d * (1 - mult))\n",
    "    _d = spectrum[spectrum_start:spectrum_end] ** 2\n",
    "\n",
    "    _zeros = torch.zeros(spectrum_end - spectrum_start)\n",
    "    _mult = (\n",
    "        _zeros\n",
    "        if boot_count >= 0\n",
    "        else torch.where(\n",
    "            _d > noise_spectrum[spectrum_start:spectrum_end],\n",
    "            torch.tensor(noise_up_time_mult),  # if\n",
    "            torch.tensor(noise_down_time_mult),  # else\n",
    "        )\n",
    "    )\n",
    "\n",
    "    noise_spectrum[spectrum_start:spectrum_end].mul_(_mult).add_(_d * (1 - _mult))\n",
    "    _d = torch.sqrt(\n",
    "        torch.max(\n",
    "            _zeros,\n",
    "            _d - noise_reduction_amount * noise_spectrum[spectrum_start:spectrum_end],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _cepstrum_Buf: Tensor = torch.zeros(dft_len_ws >> 1)\n",
    "    _cepstrum_Buf[spectrum_start:spectrum_end] = _d * cepstrum_window\n",
    "    _cepstrum_Buf[spectrum_end: dft_len_ws >> 1].zero_()\n",
    "\n",
    "    # lsx_safe_rdft((int)p->dft_len_ws >> 1, 1, c->dftBuf);\n",
    "    _cepstrum_Buf = torch.fft.rfft(_cepstrum_Buf)\n",
    "\n",
    "    result: float = float(torch.sum(_cepstrum_Buf[cepstrum_start:cepstrum_end].abs().pow(2)))\n",
    "    result = math.log(result / (cepstrum_end - cepstrum_start)) if result > 0 else -math.inf\n",
    "    return max(0, 21 + result)\n",
    "\n",
    "\n",
    "def vad(\n",
    "    waveform: Tensor,\n",
    "    sample_rate: int,\n",
    "    trigger_level: float = 7.0,\n",
    "    trigger_time: float = 0.25,\n",
    "    search_time: float = 1.0,\n",
    "    allowed_gap: float = 0.25,\n",
    "    pre_trigger_time: float = 0.0,\n",
    "    # Fine-tuning parameters\n",
    "    boot_time: float = 0.35,\n",
    "    noise_up_time: float = 0.1,\n",
    "    noise_down_time: float = 0.01,\n",
    "    noise_reduction_amount: float = 1.35,\n",
    "    measure_freq: float = 20.0,\n",
    "    measure_duration: Optional[float] = None,\n",
    "    measure_smooth_time: float = 0.4,\n",
    "    hp_filter_freq: float = 50.0,\n",
    "    lp_filter_freq: float = 6000.0,\n",
    "    hp_lifter_freq: float = 150.0,\n",
    "    lp_lifter_freq: float = 2000.0,\n",
    ") -> tuple[Tensor, int]:\n",
    "    r\"\"\"Voice Activity Detector. Similar to SoX implementation.\n",
    "\n",
    "    .. devices:: CPU CUDA\n",
    "\n",
    "    .. properties:: TorchScript\n",
    "\n",
    "    Attempts to trim silence and quiet background sounds from the ends of recordings of speech.\n",
    "    The algorithm currently uses a simple cepstral power measurement to detect voice,\n",
    "    so may be fooled by other things, especially music.\n",
    "\n",
    "    The effect can trim only from the front of the audio,\n",
    "    so in order to trim from the back, the reverse effect must also be used.\n",
    "\n",
    "    Args:\n",
    "        waveform (Tensor): Tensor of audio of dimension `(channels, time)` or `(time)`\n",
    "            Tensor of shape `(channels, time)` is treated as a multi-channel recording\n",
    "            of the same event and the resulting output will be trimmed to the earliest\n",
    "            voice activity in any channel.\n",
    "        sample_rate (int): Sample rate of audio signal.\n",
    "        trigger_level (float, optional): The measurement level used to trigger activity detection.\n",
    "            This may need to be cahnged depending on the noise level, signal level,\n",
    "            and other characteristics of the input audio. (Default: 7.0)\n",
    "        trigger_time (float, optional): The time constant (in seconds)\n",
    "            used to help ignore short bursts of sound. (Default: 0.25)\n",
    "        search_time (float, optional): The amount of audio (in seconds)\n",
    "            to search for quieter/shorter bursts of audio to include prior\n",
    "            to the detected trigger point. (Default: 1.0)\n",
    "        allowed_gap (float, optional): The allowed gap (in seconds) between\n",
    "            quieter/shorter bursts of audio to include prior\n",
    "            to the detected trigger point. (Default: 0.25)\n",
    "        pre_trigger_time (float, optional): The amount of audio (in seconds) to preserve\n",
    "            before the trigger point and any found quieter/shorter bursts. (Default: 0.0)\n",
    "        boot_time (float, optional) The algorithm (internally) uses adaptive noise\n",
    "            estimation/reduction in order to detect the start of the wanted audio.\n",
    "            This option sets the time for the initial noise estimate. (Default: 0.35)\n",
    "        noise_up_time (float, optional) Time constant used by the adaptive noise estimator\n",
    "            for when the noise level is increasing. (Default: 0.1)\n",
    "        noise_down_time (float, optional) Time constant used by the adaptive noise estimator\n",
    "            for when the noise level is decreasing. (Default: 0.01)\n",
    "        noise_reduction_amount (float, optional) Amount of noise reduction to use in\n",
    "            the detection algorithm (e.g. 0, 0.5, ...). (Default: 1.35)\n",
    "        measure_freq (float, optional) Frequency of the algorithm’s\n",
    "            processing/measurements. (Default: 20.0)\n",
    "        measure_duration: (float, optional) Measurement duration.\n",
    "            (Default: Twice the measurement period; i.e. with overlap.)\n",
    "        measure_smooth_time (float, optional) Time constant used to smooth\n",
    "            spectral measurements. (Default: 0.4)\n",
    "        hp_filter_freq (float, optional) \"Brick-wall\" frequency of high-pass filter applied\n",
    "            at the input to the detector algorithm. (Default: 50.0)\n",
    "        lp_filter_freq (float, optional) \"Brick-wall\" frequency of low-pass filter applied\n",
    "            at the input to the detector algorithm. (Default: 6000.0)\n",
    "        hp_lifter_freq (float, optional) \"Brick-wall\" frequency of high-pass lifter used\n",
    "            in the detector algorithm. (Default: 150.0)\n",
    "        lp_lifter_freq (float, optional) \"Brick-wall\" frequency of low-pass lifter used\n",
    "            in the detector algorithm. (Default: 2000.0)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Tensor of audio of dimension `(..., time)`.\n",
    "\n",
    "    Reference:\n",
    "        - http://sox.sourceforge.net/sox.html\n",
    "    \"\"\"\n",
    "\n",
    "    if waveform.ndim > 2:\n",
    "        warnings.warn(\n",
    "            \"Expected input tensor dimension of 1 for single channel\"\n",
    "            f\" or 2 for multi-channel. Got {waveform.ndim} instead. \"\n",
    "            \"Batch semantics is not supported. \"\n",
    "            \"Please refer to https://github.com/pytorch/audio/issues/1348\"\n",
    "            \" and https://github.com/pytorch/audio/issues/1468.\"\n",
    "        )\n",
    "\n",
    "    measure_duration: float = 2.0 / measure_freq if measure_duration is None else measure_duration\n",
    "\n",
    "    measure_len_ws = int(sample_rate * measure_duration + 0.5)\n",
    "    measure_len_ns = measure_len_ws\n",
    "    # for (dft_len_ws = 16; dft_len_ws < measure_len_ws; dft_len_ws <<= 1);\n",
    "    dft_len_ws = 16\n",
    "    while dft_len_ws < measure_len_ws:\n",
    "        dft_len_ws *= 2\n",
    "\n",
    "    measure_period_ns = int(sample_rate / measure_freq + 0.5)\n",
    "    measures_len = math.ceil(search_time * measure_freq)\n",
    "    search_pre_trigger_len_ns = measures_len * measure_period_ns\n",
    "    gap_len = int(allowed_gap * measure_freq + 0.5)\n",
    "\n",
    "    fixed_pre_trigger_len_ns = int(pre_trigger_time * sample_rate + 0.5)\n",
    "    samplesLen_ns = fixed_pre_trigger_len_ns + search_pre_trigger_len_ns + measure_len_ns\n",
    "\n",
    "    spectrum_window = torch.zeros(measure_len_ws)\n",
    "    for i in range(measure_len_ws):\n",
    "        # sox.h:741 define SOX_SAMPLE_MIN (sox_sample_t)SOX_INT_MIN(32)\n",
    "        spectrum_window[i] = 2.0 / math.sqrt(float(measure_len_ws))\n",
    "    # lsx_apply_hann(spectrum_window, (int)measure_len_ws);\n",
    "    spectrum_window *= torch.hann_window(measure_len_ws, dtype=torch.float)\n",
    "\n",
    "    spectrum_start: int = int(hp_filter_freq / sample_rate * dft_len_ws + 0.5)\n",
    "    spectrum_start: int = max(spectrum_start, 1)\n",
    "    spectrum_end: int = int(lp_filter_freq / sample_rate * dft_len_ws + 0.5)\n",
    "    spectrum_end: int = min(spectrum_end, dft_len_ws // 2)\n",
    "\n",
    "    cepstrum_window = torch.zeros(spectrum_end - spectrum_start)\n",
    "    for i in range(spectrum_end - spectrum_start):\n",
    "        cepstrum_window[i] = 2.0 / math.sqrt(float(spectrum_end) - spectrum_start)\n",
    "    # lsx_apply_hann(cepstrum_window,(int)(spectrum_end - spectrum_start));\n",
    "    cepstrum_window *= torch.hann_window(spectrum_end - spectrum_start, dtype=torch.float)\n",
    "\n",
    "    cepstrum_start = math.ceil(sample_rate * 0.5 / lp_lifter_freq)\n",
    "    cepstrum_end = math.floor(sample_rate * 0.5 / hp_lifter_freq)\n",
    "    cepstrum_end = min(cepstrum_end, dft_len_ws // 4)\n",
    "\n",
    "    assert cepstrum_end > cepstrum_start\n",
    "\n",
    "    noise_up_time_mult = math.exp(-1.0 / (noise_up_time * measure_freq))\n",
    "    noise_down_time_mult = math.exp(-1.0 / (noise_down_time * measure_freq))\n",
    "    measure_smooth_time_mult = math.exp(-1.0 / (measure_smooth_time * measure_freq))\n",
    "    trigger_meas_time_mult = math.exp(-1.0 / (trigger_time * measure_freq))\n",
    "\n",
    "    boot_count_max = int(boot_time * measure_freq - 0.5)\n",
    "    measure_timer_ns = measure_len_ns\n",
    "    boot_count = measures_index = flushedLen_ns = samplesIndex_ns = 0\n",
    "\n",
    "    # pack batch\n",
    "    shape = waveform.size()\n",
    "    waveform = waveform.view(-1, shape[-1])\n",
    "\n",
    "    n_channels, ilen = waveform.size()\n",
    "\n",
    "    mean_meas = torch.zeros(n_channels)\n",
    "    samples = torch.zeros(n_channels, samplesLen_ns)\n",
    "    spectrum = torch.zeros(n_channels, dft_len_ws)\n",
    "    noise_spectrum = torch.zeros(n_channels, dft_len_ws)\n",
    "    measures = torch.zeros(n_channels, measures_len)\n",
    "\n",
    "    has_triggered: bool = False\n",
    "    num_measures_to_flush: int = 0\n",
    "    pos: int = 0\n",
    "\n",
    "    while pos < ilen and not has_triggered:\n",
    "        measure_timer_ns -= 1\n",
    "        for i in range(n_channels):\n",
    "            samples[i, samplesIndex_ns] = waveform[i, pos]\n",
    "            # if (!p->measure_timer_ns) {\n",
    "            if measure_timer_ns == 0:\n",
    "                index_ns: int = (samplesIndex_ns + samplesLen_ns - measure_len_ns) % samplesLen_ns\n",
    "                meas: float = _measure(\n",
    "                    measure_len_ws=measure_len_ws,\n",
    "                    samples=samples[i],\n",
    "                    spectrum=spectrum[i],\n",
    "                    noise_spectrum=noise_spectrum[i],\n",
    "                    spectrum_window=spectrum_window,\n",
    "                    spectrum_start=spectrum_start,\n",
    "                    spectrum_end=spectrum_end,\n",
    "                    cepstrum_window=cepstrum_window,\n",
    "                    cepstrum_start=cepstrum_start,\n",
    "                    cepstrum_end=cepstrum_end,\n",
    "                    noise_reduction_amount=noise_reduction_amount,\n",
    "                    measure_smooth_time_mult=measure_smooth_time_mult,\n",
    "                    noise_up_time_mult=noise_up_time_mult,\n",
    "                    noise_down_time_mult=noise_down_time_mult,\n",
    "                    index_ns=index_ns,\n",
    "                    boot_count=boot_count,\n",
    "                )\n",
    "                measures[i, measures_index] = meas\n",
    "                mean_meas[i] = mean_meas[i] * trigger_meas_time_mult + meas * (1.0 - trigger_meas_time_mult)\n",
    "\n",
    "                has_triggered = has_triggered or (mean_meas[i] >= trigger_level)\n",
    "                if has_triggered:\n",
    "                    n: int = measures_len\n",
    "                    k: int = measures_index\n",
    "                    jTrigger: int = n\n",
    "                    jZero: int = n\n",
    "                    j: int = 0\n",
    "\n",
    "                    for j in range(n):\n",
    "                        if (measures[i, k] >= trigger_level) and (j <= jTrigger + gap_len):\n",
    "                            jZero = jTrigger = j\n",
    "                        elif (measures[i, k] == 0) and (jTrigger >= jZero):\n",
    "                            jZero = j\n",
    "                        k = (k + n - 1) % n\n",
    "                    j = min(j, jZero)\n",
    "                    # num_measures_to_flush = range_limit(j, num_measures_to_flush, n);\n",
    "                    num_measures_to_flush = min(max(num_measures_to_flush, j), n)\n",
    "                # end if has_triggered\n",
    "            # end if (measure_timer_ns == 0):\n",
    "        # end for\n",
    "        samplesIndex_ns += 1\n",
    "        pos += 1\n",
    "        # end while\n",
    "        if samplesIndex_ns == samplesLen_ns:\n",
    "            samplesIndex_ns = 0\n",
    "        if measure_timer_ns == 0:\n",
    "            measure_timer_ns = measure_period_ns\n",
    "            measures_index += 1\n",
    "            measures_index = measures_index % measures_len\n",
    "            if boot_count >= 0:\n",
    "                boot_count = -1 if boot_count == boot_count_max else boot_count + 1\n",
    "\n",
    "        if has_triggered:\n",
    "            flushedLen_ns = (measures_len - num_measures_to_flush) * measure_period_ns\n",
    "            samplesIndex_ns = (samplesIndex_ns + flushedLen_ns) % samplesLen_ns\n",
    "\n",
    "    res = waveform[:, pos - samplesLen_ns + flushedLen_ns:]\n",
    "    # unpack batch\n",
    "    return res.view(shape[:-1] + res.shape[-1:]), pos - samplesLen_ns + flushedLen_ns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 53760]) 16000\n"
     ]
    }
   ],
   "source": [
    "wav, sr = torchaudio.load(\"../dataSet/문제3/문제3-2.wav\")\n",
    "print(wav.shape, sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c + 1}\")\n",
    "    figure.suptitle(\"waveform\")\n",
    "    plt.show(block=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_waveform(wav, sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400 48960 53760\n"
     ]
    }
   ],
   "source": [
    "vad_wav, begin_idx = vad(wav, sr)\n",
    "vad_wav, reverse_begin_idx = vad(vad_wav.flip(dims=[-1]), sr)\n",
    "vad_wav = vad_wav.flip(dims=[-1])\n",
    "torch.all(vad_wav == wav[:, begin_idx:-reverse_begin_idx])\n",
    "\n",
    "print(begin_idx, wav.shape[-1] - reverse_begin_idx, wav.shape[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# torchaudio.save(\"문제3-2_vad.wav\", vad_wav, sr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}